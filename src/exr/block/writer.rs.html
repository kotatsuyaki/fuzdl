<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><meta name="generator" content="rustdoc"><meta name="description" content="Source of the Rust file `/home/runner/.cargo/registry/src/github.com-1ecc6299db9ec823/exr-1.5.0/src/block/writer.rs`."><meta name="keywords" content="rust, rustlang, rust-lang"><title>writer.rs - source</title><link rel="preload" as="font" type="font/woff2" crossorigin href="../../../SourceSerif4-Regular.ttf.woff2"><link rel="preload" as="font" type="font/woff2" crossorigin href="../../../FiraSans-Regular.woff2"><link rel="preload" as="font" type="font/woff2" crossorigin href="../../../FiraSans-Medium.woff2"><link rel="preload" as="font" type="font/woff2" crossorigin href="../../../SourceCodePro-Regular.ttf.woff2"><link rel="preload" as="font" type="font/woff2" crossorigin href="../../../SourceSerif4-Bold.ttf.woff2"><link rel="preload" as="font" type="font/woff2" crossorigin href="../../../SourceCodePro-Semibold.ttf.woff2"><link rel="stylesheet" href="../../../normalize.css"><link rel="stylesheet" href="../../../rustdoc.css" id="mainThemeStyle"><link rel="stylesheet" href="../../../ayu.css" disabled><link rel="stylesheet" href="../../../dark.css" disabled><link rel="stylesheet" href="../../../light.css" id="themeStyle"><script id="default-settings" ></script><script src="../../../storage.js"></script><script defer src="../../../source-script.js"></script><script defer src="../../../source-files.js"></script><script defer src="../../../main.js"></script><noscript><link rel="stylesheet" href="../../../noscript.css"></noscript><link rel="alternate icon" type="image/png" href="../../../favicon-16x16.png"><link rel="alternate icon" type="image/png" href="../../../favicon-32x32.png"><link rel="icon" type="image/svg+xml" href="../../../favicon.svg"></head><body class="rustdoc source"><!--[if lte IE 11]><div class="warning">This old browser is unsupported and will most likely display funky things.</div><![endif]--><nav class="mobile-topbar"><button class="sidebar-menu-toggle">&#9776;</button><a class="sidebar-logo" href="../../../exr/index.html"><div class="logo-container"><img class="rust-logo" src="../../../rust-logo.svg" alt="logo"></div></a><h2 class="location"></h2></nav><nav class="sidebar"><a class="sidebar-logo" href="../../../exr/index.html"><div class="logo-container"><img class="rust-logo" src="../../../rust-logo.svg" alt="logo"></div></a></nav><main><div class="width-limiter"><div class="sub-container"><a class="sub-logo-container" href="../../../exr/index.html"><img class="rust-logo" src="../../../rust-logo.svg" alt="logo"></a><nav class="sub"><form class="search-form"><div class="search-container"><span></span><input class="search-input" name="search" autocomplete="off" spellcheck="false" placeholder="Click or press ‘S’ to search, ‘?’ for more options…" type="search"><div id="help-button" title="help" tabindex="-1"><button type="button">?</button></div><div id="settings-menu" tabindex="-1"><a href="../../../settings.html" title="settings"><img width="22" height="22" alt="Change settings" src="../../../wheel.svg"></a></div></div></form></nav></div><section id="main-content" class="content"><div class="example-wrap"><pre class="line-numbers"><span id="1">1</span>
<span id="2">2</span>
<span id="3">3</span>
<span id="4">4</span>
<span id="5">5</span>
<span id="6">6</span>
<span id="7">7</span>
<span id="8">8</span>
<span id="9">9</span>
<span id="10">10</span>
<span id="11">11</span>
<span id="12">12</span>
<span id="13">13</span>
<span id="14">14</span>
<span id="15">15</span>
<span id="16">16</span>
<span id="17">17</span>
<span id="18">18</span>
<span id="19">19</span>
<span id="20">20</span>
<span id="21">21</span>
<span id="22">22</span>
<span id="23">23</span>
<span id="24">24</span>
<span id="25">25</span>
<span id="26">26</span>
<span id="27">27</span>
<span id="28">28</span>
<span id="29">29</span>
<span id="30">30</span>
<span id="31">31</span>
<span id="32">32</span>
<span id="33">33</span>
<span id="34">34</span>
<span id="35">35</span>
<span id="36">36</span>
<span id="37">37</span>
<span id="38">38</span>
<span id="39">39</span>
<span id="40">40</span>
<span id="41">41</span>
<span id="42">42</span>
<span id="43">43</span>
<span id="44">44</span>
<span id="45">45</span>
<span id="46">46</span>
<span id="47">47</span>
<span id="48">48</span>
<span id="49">49</span>
<span id="50">50</span>
<span id="51">51</span>
<span id="52">52</span>
<span id="53">53</span>
<span id="54">54</span>
<span id="55">55</span>
<span id="56">56</span>
<span id="57">57</span>
<span id="58">58</span>
<span id="59">59</span>
<span id="60">60</span>
<span id="61">61</span>
<span id="62">62</span>
<span id="63">63</span>
<span id="64">64</span>
<span id="65">65</span>
<span id="66">66</span>
<span id="67">67</span>
<span id="68">68</span>
<span id="69">69</span>
<span id="70">70</span>
<span id="71">71</span>
<span id="72">72</span>
<span id="73">73</span>
<span id="74">74</span>
<span id="75">75</span>
<span id="76">76</span>
<span id="77">77</span>
<span id="78">78</span>
<span id="79">79</span>
<span id="80">80</span>
<span id="81">81</span>
<span id="82">82</span>
<span id="83">83</span>
<span id="84">84</span>
<span id="85">85</span>
<span id="86">86</span>
<span id="87">87</span>
<span id="88">88</span>
<span id="89">89</span>
<span id="90">90</span>
<span id="91">91</span>
<span id="92">92</span>
<span id="93">93</span>
<span id="94">94</span>
<span id="95">95</span>
<span id="96">96</span>
<span id="97">97</span>
<span id="98">98</span>
<span id="99">99</span>
<span id="100">100</span>
<span id="101">101</span>
<span id="102">102</span>
<span id="103">103</span>
<span id="104">104</span>
<span id="105">105</span>
<span id="106">106</span>
<span id="107">107</span>
<span id="108">108</span>
<span id="109">109</span>
<span id="110">110</span>
<span id="111">111</span>
<span id="112">112</span>
<span id="113">113</span>
<span id="114">114</span>
<span id="115">115</span>
<span id="116">116</span>
<span id="117">117</span>
<span id="118">118</span>
<span id="119">119</span>
<span id="120">120</span>
<span id="121">121</span>
<span id="122">122</span>
<span id="123">123</span>
<span id="124">124</span>
<span id="125">125</span>
<span id="126">126</span>
<span id="127">127</span>
<span id="128">128</span>
<span id="129">129</span>
<span id="130">130</span>
<span id="131">131</span>
<span id="132">132</span>
<span id="133">133</span>
<span id="134">134</span>
<span id="135">135</span>
<span id="136">136</span>
<span id="137">137</span>
<span id="138">138</span>
<span id="139">139</span>
<span id="140">140</span>
<span id="141">141</span>
<span id="142">142</span>
<span id="143">143</span>
<span id="144">144</span>
<span id="145">145</span>
<span id="146">146</span>
<span id="147">147</span>
<span id="148">148</span>
<span id="149">149</span>
<span id="150">150</span>
<span id="151">151</span>
<span id="152">152</span>
<span id="153">153</span>
<span id="154">154</span>
<span id="155">155</span>
<span id="156">156</span>
<span id="157">157</span>
<span id="158">158</span>
<span id="159">159</span>
<span id="160">160</span>
<span id="161">161</span>
<span id="162">162</span>
<span id="163">163</span>
<span id="164">164</span>
<span id="165">165</span>
<span id="166">166</span>
<span id="167">167</span>
<span id="168">168</span>
<span id="169">169</span>
<span id="170">170</span>
<span id="171">171</span>
<span id="172">172</span>
<span id="173">173</span>
<span id="174">174</span>
<span id="175">175</span>
<span id="176">176</span>
<span id="177">177</span>
<span id="178">178</span>
<span id="179">179</span>
<span id="180">180</span>
<span id="181">181</span>
<span id="182">182</span>
<span id="183">183</span>
<span id="184">184</span>
<span id="185">185</span>
<span id="186">186</span>
<span id="187">187</span>
<span id="188">188</span>
<span id="189">189</span>
<span id="190">190</span>
<span id="191">191</span>
<span id="192">192</span>
<span id="193">193</span>
<span id="194">194</span>
<span id="195">195</span>
<span id="196">196</span>
<span id="197">197</span>
<span id="198">198</span>
<span id="199">199</span>
<span id="200">200</span>
<span id="201">201</span>
<span id="202">202</span>
<span id="203">203</span>
<span id="204">204</span>
<span id="205">205</span>
<span id="206">206</span>
<span id="207">207</span>
<span id="208">208</span>
<span id="209">209</span>
<span id="210">210</span>
<span id="211">211</span>
<span id="212">212</span>
<span id="213">213</span>
<span id="214">214</span>
<span id="215">215</span>
<span id="216">216</span>
<span id="217">217</span>
<span id="218">218</span>
<span id="219">219</span>
<span id="220">220</span>
<span id="221">221</span>
<span id="222">222</span>
<span id="223">223</span>
<span id="224">224</span>
<span id="225">225</span>
<span id="226">226</span>
<span id="227">227</span>
<span id="228">228</span>
<span id="229">229</span>
<span id="230">230</span>
<span id="231">231</span>
<span id="232">232</span>
<span id="233">233</span>
<span id="234">234</span>
<span id="235">235</span>
<span id="236">236</span>
<span id="237">237</span>
<span id="238">238</span>
<span id="239">239</span>
<span id="240">240</span>
<span id="241">241</span>
<span id="242">242</span>
<span id="243">243</span>
<span id="244">244</span>
<span id="245">245</span>
<span id="246">246</span>
<span id="247">247</span>
<span id="248">248</span>
<span id="249">249</span>
<span id="250">250</span>
<span id="251">251</span>
<span id="252">252</span>
<span id="253">253</span>
<span id="254">254</span>
<span id="255">255</span>
<span id="256">256</span>
<span id="257">257</span>
<span id="258">258</span>
<span id="259">259</span>
<span id="260">260</span>
<span id="261">261</span>
<span id="262">262</span>
<span id="263">263</span>
<span id="264">264</span>
<span id="265">265</span>
<span id="266">266</span>
<span id="267">267</span>
<span id="268">268</span>
<span id="269">269</span>
<span id="270">270</span>
<span id="271">271</span>
<span id="272">272</span>
<span id="273">273</span>
<span id="274">274</span>
<span id="275">275</span>
<span id="276">276</span>
<span id="277">277</span>
<span id="278">278</span>
<span id="279">279</span>
<span id="280">280</span>
<span id="281">281</span>
<span id="282">282</span>
<span id="283">283</span>
<span id="284">284</span>
<span id="285">285</span>
<span id="286">286</span>
<span id="287">287</span>
<span id="288">288</span>
<span id="289">289</span>
<span id="290">290</span>
<span id="291">291</span>
<span id="292">292</span>
<span id="293">293</span>
<span id="294">294</span>
<span id="295">295</span>
<span id="296">296</span>
<span id="297">297</span>
<span id="298">298</span>
<span id="299">299</span>
<span id="300">300</span>
<span id="301">301</span>
<span id="302">302</span>
<span id="303">303</span>
<span id="304">304</span>
<span id="305">305</span>
<span id="306">306</span>
<span id="307">307</span>
<span id="308">308</span>
<span id="309">309</span>
<span id="310">310</span>
<span id="311">311</span>
<span id="312">312</span>
<span id="313">313</span>
<span id="314">314</span>
<span id="315">315</span>
<span id="316">316</span>
<span id="317">317</span>
<span id="318">318</span>
<span id="319">319</span>
<span id="320">320</span>
<span id="321">321</span>
<span id="322">322</span>
<span id="323">323</span>
<span id="324">324</span>
<span id="325">325</span>
<span id="326">326</span>
<span id="327">327</span>
<span id="328">328</span>
<span id="329">329</span>
<span id="330">330</span>
<span id="331">331</span>
<span id="332">332</span>
<span id="333">333</span>
<span id="334">334</span>
<span id="335">335</span>
<span id="336">336</span>
<span id="337">337</span>
<span id="338">338</span>
<span id="339">339</span>
<span id="340">340</span>
<span id="341">341</span>
<span id="342">342</span>
<span id="343">343</span>
<span id="344">344</span>
<span id="345">345</span>
<span id="346">346</span>
<span id="347">347</span>
<span id="348">348</span>
<span id="349">349</span>
<span id="350">350</span>
<span id="351">351</span>
<span id="352">352</span>
<span id="353">353</span>
<span id="354">354</span>
<span id="355">355</span>
<span id="356">356</span>
<span id="357">357</span>
<span id="358">358</span>
<span id="359">359</span>
<span id="360">360</span>
<span id="361">361</span>
<span id="362">362</span>
<span id="363">363</span>
<span id="364">364</span>
<span id="365">365</span>
<span id="366">366</span>
<span id="367">367</span>
<span id="368">368</span>
<span id="369">369</span>
<span id="370">370</span>
<span id="371">371</span>
<span id="372">372</span>
<span id="373">373</span>
<span id="374">374</span>
<span id="375">375</span>
<span id="376">376</span>
<span id="377">377</span>
<span id="378">378</span>
<span id="379">379</span>
<span id="380">380</span>
<span id="381">381</span>
<span id="382">382</span>
<span id="383">383</span>
<span id="384">384</span>
<span id="385">385</span>
<span id="386">386</span>
<span id="387">387</span>
<span id="388">388</span>
<span id="389">389</span>
<span id="390">390</span>
<span id="391">391</span>
<span id="392">392</span>
<span id="393">393</span>
<span id="394">394</span>
<span id="395">395</span>
<span id="396">396</span>
<span id="397">397</span>
<span id="398">398</span>
<span id="399">399</span>
<span id="400">400</span>
<span id="401">401</span>
<span id="402">402</span>
<span id="403">403</span>
<span id="404">404</span>
<span id="405">405</span>
<span id="406">406</span>
<span id="407">407</span>
<span id="408">408</span>
<span id="409">409</span>
<span id="410">410</span>
<span id="411">411</span>
<span id="412">412</span>
<span id="413">413</span>
<span id="414">414</span>
<span id="415">415</span>
<span id="416">416</span>
<span id="417">417</span>
<span id="418">418</span>
<span id="419">419</span>
<span id="420">420</span>
<span id="421">421</span>
<span id="422">422</span>
<span id="423">423</span>
<span id="424">424</span>
<span id="425">425</span>
<span id="426">426</span>
<span id="427">427</span>
<span id="428">428</span>
<span id="429">429</span>
<span id="430">430</span>
<span id="431">431</span>
<span id="432">432</span>
<span id="433">433</span>
<span id="434">434</span>
<span id="435">435</span>
<span id="436">436</span>
<span id="437">437</span>
<span id="438">438</span>
<span id="439">439</span>
<span id="440">440</span>
<span id="441">441</span>
<span id="442">442</span>
<span id="443">443</span>
<span id="444">444</span>
<span id="445">445</span>
<span id="446">446</span>
<span id="447">447</span>
<span id="448">448</span>
<span id="449">449</span>
<span id="450">450</span>
<span id="451">451</span>
<span id="452">452</span>
<span id="453">453</span>
<span id="454">454</span>
<span id="455">455</span>
</pre><pre class="rust"><code><span class="doccomment">//! Composable structures to handle writing an image.


</span><span class="kw">use </span>std::fmt::Debug;
<span class="kw">use </span>std::io::Seek;
<span class="kw">use </span>std::iter::Peekable;
<span class="kw">use </span>std::ops::Not;

<span class="kw">use </span>smallvec::alloc::collections::BTreeMap;

<span class="kw">use </span><span class="kw">crate</span>::block::UncompressedBlock;
<span class="kw">use </span><span class="kw">crate</span>::block::chunk::{Chunk};
<span class="kw">use </span><span class="kw">crate</span>::compression::Compression;
<span class="kw">use </span><span class="kw">crate</span>::error::{Error, <span class="prelude-ty">Result</span>, UnitResult, usize_to_u64};
<span class="kw">use </span><span class="kw">crate</span>::io::{Data, Tracking, Write};
<span class="kw">use </span><span class="kw">crate</span>::meta::{Headers, MetaData, OffsetTables};
<span class="kw">use </span><span class="kw">crate</span>::meta::attribute::LineOrder;

<span class="doccomment">/// Write an exr file by writing one chunk after another in a closure.
/// In the closure, you are provided a chunk writer, which should be used to write all the chunks.
/// Assumes the your write destination is buffered.
</span><span class="kw">pub fn </span>write_chunks_with&lt;W: Write + Seek&gt;(
    buffered_write: W, headers: Headers, pedantic: bool,
    write_chunks: <span class="kw">impl </span>FnOnce(MetaData, <span class="kw-2">&amp;mut </span>ChunkWriter&lt;W&gt;) -&gt; UnitResult
) -&gt; UnitResult {
    <span class="comment">// this closure approach ensures that after writing all chunks, the file is always completed and checked and flushed
    </span><span class="kw">let </span>(meta, <span class="kw-2">mut </span>writer) = ChunkWriter::new_for_buffered(buffered_write, headers, pedantic)<span class="question-mark">?</span>;
    write_chunks(meta, <span class="kw-2">&amp;mut </span>writer)<span class="question-mark">?</span>;
    writer.complete_meta_data()
}

<span class="doccomment">/// Can consume compressed pixel chunks, writing them a file.
/// Use `sequential_blocks_compressor` or `parallel_blocks_compressor` to compress your data,
/// or use `compress_all_blocks_sequential` or `compress_all_blocks_parallel`.
/// Use `on_progress` to obtain a new writer
/// that triggers a callback for each block.
</span><span class="comment">// #[must_use]
</span><span class="attribute">#[derive(Debug)]
#[must_use]
</span><span class="kw">pub struct </span>ChunkWriter&lt;W&gt; {
    header_count: usize,
    byte_writer: Tracking&lt;W&gt;,
    chunk_indices_byte_location: std::ops::Range&lt;usize&gt;,
    chunk_indices_increasing_y: OffsetTables,
    chunk_count: usize, <span class="comment">// TODO compose?
</span>}

<span class="doccomment">/// A new writer that triggers a callback
/// for each block written to the inner writer.
</span><span class="attribute">#[derive(Debug)]
#[must_use]
</span><span class="kw">pub struct </span>OnProgressChunkWriter&lt;<span class="lifetime">&#39;w</span>, W, F&gt; {
    chunk_writer: <span class="kw-2">&amp;</span><span class="lifetime">&#39;w </span><span class="kw-2">mut </span>W,
    written_chunks: usize,
    on_progress: F,
}

<span class="doccomment">/// Write chunks to a byte destination.
/// Then write each chunk with `writer.write_chunk(chunk)`.
</span><span class="kw">pub trait </span>ChunksWriter: Sized {

    <span class="doccomment">/// The total number of chunks that the complete file will contain.
    </span><span class="kw">fn </span>total_chunks_count(<span class="kw-2">&amp;</span><span class="self">self</span>) -&gt; usize;

    <span class="doccomment">/// Any more calls will result in an error and have no effect.
    /// If writing results in an error, the file and the writer
    /// may remain in an invalid state and should not be used further.
    /// Errors when the chunk at this index was already written.
    </span><span class="kw">fn </span>write_chunk(<span class="kw-2">&amp;mut </span><span class="self">self</span>, index_in_header_increasing_y: usize, chunk: Chunk) -&gt; UnitResult;

    <span class="doccomment">/// Obtain a new writer that calls the specified closure for each block that is written to this writer.
    </span><span class="kw">fn </span>on_progress&lt;F&gt;(<span class="kw-2">&amp;mut </span><span class="self">self</span>, on_progress: F) -&gt; OnProgressChunkWriter&lt;<span class="lifetime">&#39;_</span>, <span class="self">Self</span>, F&gt; <span class="kw">where </span>F: FnMut(f64) {
        OnProgressChunkWriter { chunk_writer: <span class="self">self</span>, written_chunks: <span class="number">0</span>, on_progress }
    }

    <span class="doccomment">/// Obtain a new writer that can compress blocks to chunks, which are then passed to this writer.
    </span><span class="kw">fn </span>sequential_blocks_compressor&lt;<span class="lifetime">&#39;w</span>&gt;(<span class="kw-2">&amp;</span><span class="lifetime">&#39;w </span><span class="kw-2">mut </span><span class="self">self</span>, meta: <span class="kw-2">&amp;</span><span class="lifetime">&#39;w </span>MetaData) -&gt; SequentialBlocksCompressor&lt;<span class="lifetime">&#39;w</span>, <span class="self">Self</span>&gt; {
        SequentialBlocksCompressor::new(meta, <span class="self">self</span>)
    }

    <span class="doccomment">/// Obtain a new writer that can compress blocks to chunks on multiple threads, which are then passed to this writer.
    /// Returns none if the sequential compressor should be used instead (thread pool creation failure or too large performance overhead).
    </span><span class="kw">fn </span>parallel_blocks_compressor&lt;<span class="lifetime">&#39;w</span>&gt;(<span class="kw-2">&amp;</span><span class="lifetime">&#39;w </span><span class="kw-2">mut </span><span class="self">self</span>, meta: <span class="kw-2">&amp;</span><span class="lifetime">&#39;w </span>MetaData) -&gt; <span class="prelude-ty">Option</span>&lt;ParallelBlocksCompressor&lt;<span class="lifetime">&#39;w</span>, <span class="self">Self</span>&gt;&gt; {
        <span class="kw">let </span>pool = threadpool::Builder::new()
            .thread_name(<span class="string">&quot;OpenEXR Block Compressor&quot;</span>.to_string())
            <span class="comment">// todo no more threads than remaining block count (self.len())
            </span>.build();

        ParallelBlocksCompressor::new(meta, <span class="self">self</span>, pool)
    }

    <span class="doccomment">/// Compresses all blocks to the file.
    /// The index of the block must be in increasing line order within the header.
    /// Obtain iterator with `MetaData::collect_ordered_blocks(...)` or similar methods.
    </span><span class="kw">fn </span>compress_all_blocks_sequential(<span class="kw-2">mut </span><span class="self">self</span>, meta: <span class="kw-2">&amp;</span>MetaData, blocks: <span class="kw">impl </span>Iterator&lt;Item=(usize, UncompressedBlock)&gt;) -&gt; UnitResult {
        <span class="kw">let </span><span class="kw-2">mut </span>writer = <span class="self">self</span>.sequential_blocks_compressor(meta);

        <span class="comment">// TODO check block order if line order is not unspecified!
        </span><span class="kw">for </span>(index_in_header_increasing_y, block) <span class="kw">in </span>blocks {
            writer.compress_block(index_in_header_increasing_y, block)<span class="question-mark">?</span>;
        }

        <span class="comment">// TODO debug_assert_eq!(self.is_complete());
        </span><span class="prelude-val">Ok</span>(())
    }

    <span class="doccomment">/// Compresses all blocks to the file.
    /// The index of the block must be in increasing line order within the header.
    /// Obtain iterator with `MetaData::collect_ordered_blocks(...)` or similar methods.
    </span><span class="kw">fn </span>compress_all_blocks_parallel(<span class="kw-2">mut </span><span class="self">self</span>, meta: <span class="kw-2">&amp;</span>MetaData, blocks: <span class="kw">impl </span>Iterator&lt;Item=(usize, UncompressedBlock)&gt;) -&gt; UnitResult {
        <span class="kw">let </span><span class="kw-2">mut </span>parallel_writer = <span class="kw">match </span><span class="self">self</span>.parallel_blocks_compressor(meta) {
            <span class="prelude-val">None </span>=&gt; <span class="kw">return </span><span class="self">self</span>.compress_all_blocks_sequential(meta, blocks),
            <span class="prelude-val">Some</span>(writer) =&gt; writer,
        };

        <span class="comment">// TODO check block order if line order is not unspecified!
        </span><span class="kw">for </span>(index_in_header_increasing_y, block) <span class="kw">in </span>blocks {
            parallel_writer.add_block_to_compression_queue(index_in_header_increasing_y, block)<span class="question-mark">?</span>;
        }

        <span class="comment">// TODO debug_assert_eq!(self.is_complete());
        </span><span class="prelude-val">Ok</span>(())
    }
}


<span class="kw">impl</span>&lt;W&gt; ChunksWriter <span class="kw">for </span>ChunkWriter&lt;W&gt; <span class="kw">where </span>W: Write + Seek {

    <span class="doccomment">/// The total number of chunks that the complete file will contain.
    </span><span class="kw">fn </span>total_chunks_count(<span class="kw-2">&amp;</span><span class="self">self</span>) -&gt; usize { <span class="self">self</span>.chunk_count }

    <span class="doccomment">/// Any more calls will result in an error and have no effect.
    /// If writing results in an error, the file and the writer
    /// may remain in an invalid state and should not be used further.
    /// Errors when the chunk at this index was already written.
    </span><span class="kw">fn </span>write_chunk(<span class="kw-2">&amp;mut </span><span class="self">self</span>, index_in_header_increasing_y: usize, chunk: Chunk) -&gt; UnitResult {
        <span class="kw">let </span>header_chunk_indices = <span class="kw-2">&amp;mut </span><span class="self">self</span>.chunk_indices_increasing_y[chunk.layer_index];

        <span class="kw">if </span>index_in_header_increasing_y &gt;= header_chunk_indices.len() {
            <span class="kw">return </span><span class="prelude-val">Err</span>(Error::invalid(<span class="string">&quot;too large chunk index&quot;</span>));
        }

        <span class="kw">let </span>chunk_index_slot = <span class="kw-2">&amp;mut </span>header_chunk_indices[index_in_header_increasing_y];
        <span class="kw">if </span><span class="kw-2">*</span>chunk_index_slot != <span class="number">0 </span>{
            <span class="kw">return </span><span class="prelude-val">Err</span>(Error::invalid(<span class="macro">format!</span>(<span class="string">&quot;chunk at index {} is already written&quot;</span>, index_in_header_increasing_y)));
        }

        <span class="kw-2">*</span>chunk_index_slot = usize_to_u64(<span class="self">self</span>.byte_writer.byte_position());
        chunk.write(<span class="kw-2">&amp;mut </span><span class="self">self</span>.byte_writer, <span class="self">self</span>.header_count)<span class="question-mark">?</span>;
        <span class="prelude-val">Ok</span>(())
    }
}

<span class="kw">impl</span>&lt;W&gt; ChunkWriter&lt;W&gt; <span class="kw">where </span>W: Write + Seek {
    <span class="comment">// -- the following functions are private, because they must be called in a strict order --

    </span><span class="doccomment">/// Writes the meta data and zeroed offset tables as a placeholder.
    </span><span class="kw">fn </span>new_for_buffered(buffered_byte_writer: W, headers: Headers, pedantic: bool) -&gt; <span class="prelude-ty">Result</span>&lt;(MetaData, <span class="self">Self</span>)&gt; {
        <span class="kw">let </span><span class="kw-2">mut </span>write = Tracking::new(buffered_byte_writer);
        <span class="kw">let </span>requirements = MetaData::write_validating_to_buffered(<span class="kw-2">&amp;mut </span>write, headers.as_slice(), pedantic)<span class="question-mark">?</span>;

        <span class="comment">// TODO: use increasing line order where possible, but this requires us to know whether we want to be parallel right now
        /*// if non-parallel compression, we always use increasing order anyways
        if !parallel || !has_compression {
            for header in &amp;mut headers {
                if header.line_order == LineOrder::Unspecified {
                    header.line_order = LineOrder::Increasing;
                }
            }
        }*/

        </span><span class="kw">let </span>offset_table_size: usize = headers.iter().map(|header| header.chunk_count).sum();

        <span class="kw">let </span>offset_table_start_byte = write.byte_position();
        <span class="kw">let </span>offset_table_end_byte = write.byte_position() + offset_table_size * u64::BYTE_SIZE;

        <span class="comment">// skip offset tables, filling with 0, will be updated after the last chunk has been written
        </span>write.seek_write_to(offset_table_end_byte)<span class="question-mark">?</span>;

        <span class="kw">let </span>header_count = headers.len();
        <span class="kw">let </span>chunk_indices_increasing_y = headers.iter()
            .map(|header| <span class="macro">vec!</span>[<span class="number">0_u64</span>; header.chunk_count]).collect();

        <span class="kw">let </span>meta_data = MetaData { requirements, headers };

        <span class="prelude-val">Ok</span>((meta_data, ChunkWriter {
            header_count,
            byte_writer: write,
            chunk_count: offset_table_size,
            chunk_indices_byte_location: offset_table_start_byte .. offset_table_end_byte,
            chunk_indices_increasing_y,
        }))
    }

    <span class="doccomment">/// Seek back to the meta data, write offset tables, and flush the byte writer.
    /// Leaves the writer seeked to the middle of the file.
    </span><span class="kw">fn </span>complete_meta_data(<span class="kw-2">mut </span><span class="self">self</span>) -&gt; UnitResult {
        <span class="kw">if </span><span class="self">self</span>.chunk_indices_increasing_y.iter().flatten().any(|<span class="kw-2">&amp;</span>index| index == <span class="number">0</span>) {
            <span class="kw">return </span><span class="prelude-val">Err</span>(Error::invalid(<span class="string">&quot;some chunks are not written yet&quot;</span>))
        }

        <span class="comment">// write all offset tables
        </span><span class="macro">debug_assert_ne!</span>(<span class="self">self</span>.byte_writer.byte_position(), <span class="self">self</span>.chunk_indices_byte_location.end, <span class="string">&quot;offset table has already been updated&quot;</span>);
        <span class="self">self</span>.byte_writer.seek_write_to(<span class="self">self</span>.chunk_indices_byte_location.start)<span class="question-mark">?</span>;

        <span class="kw">for </span>table <span class="kw">in </span><span class="self">self</span>.chunk_indices_increasing_y {
            u64::write_slice(<span class="kw-2">&amp;mut </span><span class="self">self</span>.byte_writer, table.as_slice())<span class="question-mark">?</span>;
        }

        <span class="self">self</span>.byte_writer.flush()<span class="question-mark">?</span>; <span class="comment">// make sure we catch all (possibly delayed) io errors before returning
        </span><span class="prelude-val">Ok</span>(())
    }

}


<span class="kw">impl</span>&lt;<span class="lifetime">&#39;w</span>, W, F&gt; ChunksWriter <span class="kw">for </span>OnProgressChunkWriter&lt;<span class="lifetime">&#39;w</span>, W, F&gt; <span class="kw">where </span>W: <span class="lifetime">&#39;w </span>+ ChunksWriter, F: FnMut(f64) {
    <span class="kw">fn </span>total_chunks_count(<span class="kw-2">&amp;</span><span class="self">self</span>) -&gt; usize {
        <span class="self">self</span>.chunk_writer.total_chunks_count()
    }

    <span class="kw">fn </span>write_chunk(<span class="kw-2">&amp;mut </span><span class="self">self</span>, index_in_header_increasing_y: usize, chunk: Chunk) -&gt; UnitResult {
        <span class="kw">let </span>total_chunks = <span class="self">self</span>.total_chunks_count();
        <span class="kw">let </span>on_progress = <span class="kw-2">&amp;mut </span><span class="self">self</span>.on_progress;

        <span class="comment">// guarantee on_progress being called with 0 once
        </span><span class="kw">if </span><span class="self">self</span>.written_chunks == <span class="number">0 </span>{ on_progress(<span class="number">0.0</span>); }

        <span class="self">self</span>.chunk_writer.write_chunk(index_in_header_increasing_y, chunk)<span class="question-mark">?</span>;

        <span class="self">self</span>.written_chunks += <span class="number">1</span>;

        on_progress({
            <span class="comment">// guarantee finishing with progress 1.0 for last block at least once, float division might slightly differ from 1.0
            </span><span class="kw">if </span><span class="self">self</span>.written_chunks == total_chunks { <span class="number">1.0 </span>}
            <span class="kw">else </span>{ <span class="self">self</span>.written_chunks <span class="kw">as </span>f64 / total_chunks <span class="kw">as </span>f64 }
        });

        <span class="prelude-val">Ok</span>(())
    }
}


<span class="doccomment">/// Write blocks that appear in any order and reorder them before writing.
</span><span class="attribute">#[derive(Debug)]
#[must_use]
</span><span class="kw">pub struct </span>SortedBlocksWriter&lt;<span class="lifetime">&#39;w</span>, W&gt; {
    chunk_writer: <span class="kw-2">&amp;</span><span class="lifetime">&#39;w </span><span class="kw-2">mut </span>W,
    pending_chunks: BTreeMap&lt;usize, (usize, Chunk)&gt;,
    unwritten_chunk_indices: Peekable&lt;std::ops::Range&lt;usize&gt;&gt;,
    requires_sorting: bool, <span class="comment">// using this instead of Option, because of borrowing
</span>}


<span class="kw">impl</span>&lt;<span class="lifetime">&#39;w</span>, W&gt; SortedBlocksWriter&lt;<span class="lifetime">&#39;w</span>, W&gt; <span class="kw">where </span>W: ChunksWriter {

    <span class="doccomment">/// New sorting writer. Returns `None` if sorting is not required.
    </span><span class="kw">pub fn </span>new(meta_data: <span class="kw-2">&amp;</span>MetaData, chunk_writer: <span class="kw-2">&amp;</span><span class="lifetime">&#39;w </span><span class="kw-2">mut </span>W) -&gt; SortedBlocksWriter&lt;<span class="lifetime">&#39;w</span>, W&gt; {
        <span class="kw">let </span>requires_sorting = meta_data.headers.iter()
            .any(|header| header.line_order != LineOrder::Unspecified);

        <span class="kw">let </span>total_chunk_count = chunk_writer.total_chunks_count();

        SortedBlocksWriter {
            pending_chunks: BTreeMap::new(),
            unwritten_chunk_indices: (<span class="number">0 </span>.. total_chunk_count).peekable(),
            requires_sorting,
            chunk_writer
        }
    }

    <span class="doccomment">/// Write the chunk or stash it. In the closure, write all chunks that can be written now.
    </span><span class="kw">pub fn </span>write_or_stash_chunk(<span class="kw-2">&amp;mut </span><span class="self">self</span>, chunk_index_in_file: usize, chunk_y_index: usize, chunk: Chunk) -&gt; UnitResult {
        <span class="kw">if </span><span class="self">self</span>.requires_sorting.not() {
            <span class="kw">return </span><span class="self">self</span>.chunk_writer.write_chunk(chunk_y_index, chunk);
        }

        <span class="comment">// write this chunk now if possible
        </span><span class="kw">if </span><span class="self">self</span>.unwritten_chunk_indices.peek() == <span class="prelude-val">Some</span>(<span class="kw-2">&amp;</span>chunk_index_in_file){
            <span class="self">self</span>.chunk_writer.write_chunk(chunk_y_index, chunk)<span class="question-mark">?</span>;
            <span class="self">self</span>.unwritten_chunk_indices.next().expect(<span class="string">&quot;peeked chunk index is missing&quot;</span>);

            <span class="comment">// write all pending blocks that are immediate successors of this block
            </span><span class="kw">while let </span><span class="prelude-val">Some</span>((next_chunk_y_index, next_chunk)) = <span class="self">self
                </span>.unwritten_chunk_indices.peek().cloned()
                .and_then(|id| <span class="self">self</span>.pending_chunks.remove(<span class="kw-2">&amp;</span>id))
            {
                <span class="self">self</span>.chunk_writer.write_chunk(next_chunk_y_index, next_chunk)<span class="question-mark">?</span>;
                <span class="self">self</span>.unwritten_chunk_indices.next().expect(<span class="string">&quot;peeked chunk index is missing&quot;</span>);
            }
        }

        <span class="kw">else </span>{
            <span class="comment">// the argument block is not to be written now,
            // and all the pending blocks are not next up either,
            // so just stash this block
            </span><span class="self">self</span>.pending_chunks.insert(chunk_index_in_file, (chunk_y_index, chunk));
        }

        <span class="prelude-val">Ok</span>(())
    }

    <span class="doccomment">/// Where the chunks will be written to.
    </span><span class="kw">pub fn </span>inner_chunks_writer(<span class="kw-2">&amp;</span><span class="self">self</span>) -&gt; <span class="kw-2">&amp;</span>W {
        <span class="kw-2">&amp;</span><span class="self">self</span>.chunk_writer
    }
}



<span class="doccomment">/// Compress blocks to a chunk writer in this thread.
</span><span class="attribute">#[derive(Debug)]
#[must_use]
</span><span class="kw">pub struct </span>SequentialBlocksCompressor&lt;<span class="lifetime">&#39;w</span>, W&gt; {
    meta: <span class="kw-2">&amp;</span><span class="lifetime">&#39;w </span>MetaData,
    chunks_writer: <span class="kw-2">&amp;</span><span class="lifetime">&#39;w </span><span class="kw-2">mut </span>W,
}

<span class="kw">impl</span>&lt;<span class="lifetime">&#39;w</span>, W&gt; SequentialBlocksCompressor&lt;<span class="lifetime">&#39;w</span>, W&gt; <span class="kw">where </span>W: <span class="lifetime">&#39;w </span>+ ChunksWriter {

    <span class="doccomment">/// New blocks writer.
    </span><span class="kw">pub fn </span>new(meta: <span class="kw-2">&amp;</span><span class="lifetime">&#39;w </span>MetaData, chunks_writer: <span class="kw-2">&amp;</span><span class="lifetime">&#39;w </span><span class="kw-2">mut </span>W) -&gt; <span class="self">Self </span>{ <span class="self">Self </span>{ meta, chunks_writer, } }

    <span class="doccomment">/// This is where the compressed blocks are written to.
    </span><span class="kw">pub fn </span>inner_chunks_writer(<span class="kw-2">&amp;</span><span class="lifetime">&#39;w </span><span class="self">self</span>) -&gt; <span class="kw-2">&amp;</span><span class="lifetime">&#39;w </span>W { <span class="self">self</span>.chunks_writer }

    <span class="doccomment">/// Compress a single block immediately. The index of the block must be in increasing line order.
    </span><span class="kw">pub fn </span>compress_block(<span class="kw-2">&amp;mut </span><span class="self">self</span>, index_in_header_increasing_y: usize, block: UncompressedBlock) -&gt; UnitResult {
        <span class="self">self</span>.chunks_writer.write_chunk(
            index_in_header_increasing_y,
            block.compress_to_chunk(<span class="kw-2">&amp;</span><span class="self">self</span>.meta.headers)<span class="question-mark">?
        </span>)
    }
}

<span class="doccomment">/// Compress blocks to a chunk writer with multiple threads.
</span><span class="attribute">#[derive(Debug)]
#[must_use]
</span><span class="kw">pub struct </span>ParallelBlocksCompressor&lt;<span class="lifetime">&#39;w</span>, W&gt; {
    meta: <span class="kw-2">&amp;</span><span class="lifetime">&#39;w </span>MetaData,
    sorted_writer: SortedBlocksWriter&lt;<span class="lifetime">&#39;w</span>, W&gt;,

    sender: flume::Sender&lt;<span class="prelude-ty">Result</span>&lt;(usize, usize, Chunk)&gt;&gt;,
    receiver: flume::Receiver&lt;<span class="prelude-ty">Result</span>&lt;(usize, usize, Chunk)&gt;&gt;,
    pool: threadpool::ThreadPool,

    currently_compressing_count: usize,
    written_chunk_count: usize, <span class="comment">// used to check for last chunk
    </span>max_threads: usize,
    next_incoming_chunk_index: usize, <span class="comment">// used to remember original chunk order
</span>}

<span class="kw">impl</span>&lt;<span class="lifetime">&#39;w</span>, W&gt; ParallelBlocksCompressor&lt;<span class="lifetime">&#39;w</span>, W&gt; <span class="kw">where </span>W: <span class="lifetime">&#39;w </span>+ ChunksWriter {

    <span class="doccomment">/// New blocks writer. Returns none if sequential compression should be used.
    </span><span class="kw">pub fn </span>new(meta: <span class="kw-2">&amp;</span><span class="lifetime">&#39;w </span>MetaData, chunks_writer: <span class="kw-2">&amp;</span><span class="lifetime">&#39;w </span><span class="kw-2">mut </span>W, pool: threadpool::ThreadPool) -&gt; <span class="prelude-ty">Option</span>&lt;<span class="self">Self</span>&gt; {
        <span class="kw">if </span>meta.headers.iter().all(|head|head.compression == Compression::Uncompressed) {
            <span class="kw">return </span><span class="prelude-val">None</span>;
        }

        <span class="kw">let </span>max_threads = pool.max_count().max(<span class="number">1</span>).min(chunks_writer.total_chunks_count()) + <span class="number">2</span>; <span class="comment">// ca one block for each thread at all times
        </span><span class="kw">let </span>(send, recv) = flume::unbounded(); <span class="comment">// TODO bounded channel simplifies logic?

        </span><span class="prelude-val">Some</span>(<span class="self">Self </span>{
            sorted_writer: SortedBlocksWriter::new(meta, chunks_writer),
            next_incoming_chunk_index: <span class="number">0</span>,
            currently_compressing_count: <span class="number">0</span>,
            written_chunk_count: <span class="number">0</span>,
            sender: send,
            receiver: recv,
            max_threads,
            pool,
            meta,
        })
    }

    <span class="doccomment">/// This is where the compressed blocks are written to.
    </span><span class="kw">pub fn </span>inner_chunks_writer(<span class="kw-2">&amp;</span><span class="lifetime">&#39;w </span><span class="self">self</span>) -&gt; <span class="kw-2">&amp;</span><span class="lifetime">&#39;w </span>W { <span class="self">self</span>.sorted_writer.inner_chunks_writer() }

    <span class="comment">// private, as may underflow counter in release mode
    </span><span class="kw">fn </span>write_next_queued_chunk(<span class="kw-2">&amp;mut </span><span class="self">self</span>) -&gt; UnitResult {
        <span class="macro">debug_assert!</span>(<span class="self">self</span>.currently_compressing_count &gt; <span class="number">0</span>, <span class="string">&quot;cannot wait for chunks as there are none left&quot;</span>);

        <span class="macro">assert_eq!</span>( <span class="comment">// propagate panics (in release mode unlikely, but possible of course)
                    </span><span class="self">self</span>.pool.panic_count(), <span class="number">0</span>,
                    <span class="string">&quot;OpenEXR compressor thread panicked \
            (maybe a debug assertion failed) - \
            Use non-parallel decompression to see panic messages.&quot;
        </span>);

        <span class="kw">let </span>some_compressed_chunk = <span class="self">self</span>.receiver.recv()
            .expect(<span class="string">&quot;cannot receive compressed block&quot;</span>);

        <span class="self">self</span>.currently_compressing_count -= <span class="number">1</span>;
        <span class="kw">let </span>(chunk_file_index, chunk_y_index, chunk) = some_compressed_chunk<span class="question-mark">?</span>;
        <span class="self">self</span>.sorted_writer.write_or_stash_chunk(chunk_file_index, chunk_y_index, chunk)<span class="question-mark">?</span>;

        <span class="self">self</span>.written_chunk_count += <span class="number">1</span>;
        <span class="prelude-val">Ok</span>(())
    }

    <span class="doccomment">/// Wait until all currently compressing chunks in the compressor have been written.
    </span><span class="kw">pub fn </span>write_all_queued_chunks(<span class="kw-2">&amp;mut </span><span class="self">self</span>) -&gt; UnitResult {
        <span class="kw">while </span><span class="self">self</span>.currently_compressing_count &gt; <span class="number">0 </span>{
            <span class="self">self</span>.write_next_queued_chunk()<span class="question-mark">?</span>;
        }

        <span class="macro">debug_assert_eq!</span>(<span class="self">self</span>.currently_compressing_count, <span class="number">0</span>, <span class="string">&quot;counter does not match block count&quot;</span>);
        <span class="prelude-val">Ok</span>(())
    }

    <span class="doccomment">/// Add a single block to the compressor queue. The index of the block must be in increasing line order.
    /// When calling this function for the last block, this method waits until all the blocks have been written.
    /// This only works when you write as many blocks as the image expects, otherwise you can use `wait_for_all_remaining_chunks`.
    /// Waits for a block from the queue to be written, if the queue already has enough items.
    </span><span class="kw">pub fn </span>add_block_to_compression_queue(<span class="kw-2">&amp;mut </span><span class="self">self</span>, index_in_header_increasing_y: usize, block: UncompressedBlock) -&gt; UnitResult {

        <span class="comment">// if pipe is full, block to wait for a slot to free up
        </span><span class="kw">if </span><span class="self">self</span>.currently_compressing_count &gt;= <span class="self">self</span>.max_threads {
            <span class="self">self</span>.write_next_queued_chunk()<span class="question-mark">?</span>;
        }

        <span class="comment">// add the argument chunk to the compression queueue
        </span><span class="kw">let </span>index_in_file = <span class="self">self</span>.next_incoming_chunk_index;
        <span class="kw">let </span>sender = <span class="self">self</span>.sender.clone();
        <span class="kw">let </span>meta = <span class="self">self</span>.meta.clone();

        <span class="self">self</span>.pool.execute(<span class="kw">move </span>||{
            <span class="kw">let </span>compressed_or_err = block.compress_to_chunk(<span class="kw-2">&amp;</span>meta.headers);

            <span class="comment">// by now, decompressing could have failed in another thread.
            // the error is then already handled, so we simply
            // don&#39;t send the decompressed block and do nothing
            </span><span class="kw">let _ </span>= sender.send(compressed_or_err.map(<span class="kw">move </span>|compressed| (index_in_file, index_in_header_increasing_y, compressed)));
        });

        <span class="self">self</span>.currently_compressing_count += <span class="number">1</span>;
        <span class="self">self</span>.next_incoming_chunk_index += <span class="number">1</span>;

        <span class="comment">// if this is the last chunk, wait for all chunks to complete before returning
        </span><span class="kw">if </span><span class="self">self</span>.written_chunk_count + <span class="self">self</span>.currently_compressing_count == <span class="self">self</span>.inner_chunks_writer().total_chunks_count() {
            <span class="self">self</span>.write_all_queued_chunks()<span class="question-mark">?</span>;
            <span class="macro">debug_assert_eq!</span>(
                <span class="self">self</span>.written_chunk_count, <span class="self">self</span>.inner_chunks_writer().total_chunks_count(),
                <span class="string">&quot;written chunk count mismatch&quot;
            </span>);
        }


        <span class="prelude-val">Ok</span>(())
    }
}



</code></pre></div>
</section></div></main><div id="rustdoc-vars" data-root-path="../../../" data-current-crate="exr" data-themes="ayu,dark,light" data-resource-suffix="" data-rustdoc-version="1.65.0 (897e37553 2022-11-02)" ></div></body></html>